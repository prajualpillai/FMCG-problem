{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import nltk as nl\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Steps required for sentiment analysis\n",
    "## 1. Data Cleaning: Tokenization, stopword removal, stemming\n",
    "## 2. Vectorization: Text vectorization\n",
    "## 3. Text Classification: Based on content "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = fetch_20newsgroups()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "type(df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "rdf = df.data[:4]\n",
    "rdf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\",\n",
       " 'From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i\\'m in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni\\'m looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?\\n\\n* what\\'s the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i\\'ve only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\\\  twillis@ecn.purdue.edu    \\\\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n',\n",
       " 'From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nice.  It\\'s got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek\\'s address/phone number?  I\\'d like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stage 1: Convert into lower text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "clean_df1 = []\n",
    "def to_lower(data):\n",
    "    for words in data:\n",
    "        clean_df1.append(str.lower(words))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "to_lower(rdf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stage 2: Tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "ct2 = []\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "nl.download('punkt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/prajualpillai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sentance Tokenize: The sentances are broken up and stored as a 2d array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sent_tok = []\n",
    "for sent in clean_df1:\n",
    "    sent = sent_tokenize(sent)\n",
    "    sent_tok.append(sent)\n",
    "sent_tok"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[\"from: lerxst@wam.umd.edu (where's my thing)\\nsubject: what car is this!?\",\n",
       "  'nntp-posting-host: rac3.wam.umd.edu\\norganization: university of maryland, college park\\nlines: 15\\n\\n i was wondering if anyone out there could enlighten me on this car i saw\\nthe other day.',\n",
       "  'it was a 2-door sports car, looked to be from the late 60s/\\nearly 70s.',\n",
       "  'it was called a bricklin.',\n",
       "  'the doors were really small.',\n",
       "  'in addition,\\nthe front bumper was separate from the rest of the body.',\n",
       "  'this is \\nall i know.',\n",
       "  'if anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.',\n",
       "  'thanks,\\n- il\\n   ---- brought to you by your neighborhood lerxst ----'],\n",
       " ['from: guykuo@carson.u.washington.edu (guy kuo)\\nsubject: si clock poll - final call\\nsummary: final call for si clock reports\\nkeywords: si,acceleration,clock,upgrade\\narticle-i.d.',\n",
       "  ': shelley.1qvfo9innc3s\\norganization: university of washington\\nlines: 11\\nnntp-posting-host: carson.u.washington.edu\\n\\na fair number of brave souls who upgraded their si clock oscillator have\\nshared their experiences for this poll.',\n",
       "  'please send a brief message detailing\\nyour experiences with the procedure.',\n",
       "  'top speed attained, cpu rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.',\n",
       "  \"i will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll.\",\n",
       "  'thanks.',\n",
       "  'guy kuo <guykuo@u.washington.edu>'],\n",
       " [\"from: twillis@ec.ecn.purdue.edu (thomas e willis)\\nsubject: pb questions...\\norganization: purdue university engineering computer network\\ndistribution: usa\\nlines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?\",\n",
       "  'i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?',\n",
       "  \"* what's the impression of the display on the 180?\",\n",
       "  'i could probably swing\\na 180 if i got the 80mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).',\n",
       "  'could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?',\n",
       "  \"(i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\",\n",
       "  '* how well does hellcats perform?',\n",
       "  ';)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\ntom willis  \\\\  twillis@ecn.purdue.edu    \\\\    purdue electrical engineering\\n---------------------------------------------------------------------------\\n\"convictions are more dangerous enemies of truth than lies.\"',\n",
       "  '- f. w.\\nnietzsche'],\n",
       " ['from: jgreen@amber (joe green)\\nsubject: re: weitek p9000 ?',\n",
       "  'organization: harris computer systems division\\nlines: 14\\ndistribution: world\\nnntp-posting-host: amber.ssd.csd.harris.com\\nx-newsreader: tin [version 1.1 pl9]\\n\\nrobert j.c. kyanko (rob@rjck.uucp) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > anyone know about the weitek p9000 graphics chip?',\n",
       "  '> as far as the low-level stuff goes, it looks pretty nice.',\n",
       "  \"it's got this\\n> quadrilateral fill command that requires just the four points.\",\n",
       "  \"do you have weitek's address/phone number?\",\n",
       "  \"i'd like to get some information\\nabout this chip.\",\n",
       "  '--\\njoe green\\t\\t\\t\\tharris corporation\\njgreen@csd.harris.com\\t\\t\\tcomputer systems division\\n\"the only thing that really scares me is a person with no sense of humor.\"',\n",
       "  '-- jonathan winters']]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word Tokenize: Each word in each sentance is broken up and is stored as a 2d array "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Word Tokenize\n",
    "ct2 = [word_tokenize(i) for i in clean_df1]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "ct2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['from',\n",
       "  ':',\n",
       "  'lerxst',\n",
       "  '@',\n",
       "  'wam.umd.edu',\n",
       "  '(',\n",
       "  'where',\n",
       "  \"'s\",\n",
       "  'my',\n",
       "  'thing',\n",
       "  ')',\n",
       "  'subject',\n",
       "  ':',\n",
       "  'what',\n",
       "  'car',\n",
       "  'is',\n",
       "  'this',\n",
       "  '!',\n",
       "  '?',\n",
       "  'nntp-posting-host',\n",
       "  ':',\n",
       "  'rac3.wam.umd.edu',\n",
       "  'organization',\n",
       "  ':',\n",
       "  'university',\n",
       "  'of',\n",
       "  'maryland',\n",
       "  ',',\n",
       "  'college',\n",
       "  'park',\n",
       "  'lines',\n",
       "  ':',\n",
       "  '15',\n",
       "  'i',\n",
       "  'was',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'anyone',\n",
       "  'out',\n",
       "  'there',\n",
       "  'could',\n",
       "  'enlighten',\n",
       "  'me',\n",
       "  'on',\n",
       "  'this',\n",
       "  'car',\n",
       "  'i',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'other',\n",
       "  'day',\n",
       "  '.',\n",
       "  'it',\n",
       "  'was',\n",
       "  'a',\n",
       "  '2-door',\n",
       "  'sports',\n",
       "  'car',\n",
       "  ',',\n",
       "  'looked',\n",
       "  'to',\n",
       "  'be',\n",
       "  'from',\n",
       "  'the',\n",
       "  'late',\n",
       "  '60s/',\n",
       "  'early',\n",
       "  '70s',\n",
       "  '.',\n",
       "  'it',\n",
       "  'was',\n",
       "  'called',\n",
       "  'a',\n",
       "  'bricklin',\n",
       "  '.',\n",
       "  'the',\n",
       "  'doors',\n",
       "  'were',\n",
       "  'really',\n",
       "  'small',\n",
       "  '.',\n",
       "  'in',\n",
       "  'addition',\n",
       "  ',',\n",
       "  'the',\n",
       "  'front',\n",
       "  'bumper',\n",
       "  'was',\n",
       "  'separate',\n",
       "  'from',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'body',\n",
       "  '.',\n",
       "  'this',\n",
       "  'is',\n",
       "  'all',\n",
       "  'i',\n",
       "  'know',\n",
       "  '.',\n",
       "  'if',\n",
       "  'anyone',\n",
       "  'can',\n",
       "  'tellme',\n",
       "  'a',\n",
       "  'model',\n",
       "  'name',\n",
       "  ',',\n",
       "  'engine',\n",
       "  'specs',\n",
       "  ',',\n",
       "  'years',\n",
       "  'of',\n",
       "  'production',\n",
       "  ',',\n",
       "  'where',\n",
       "  'this',\n",
       "  'car',\n",
       "  'is',\n",
       "  'made',\n",
       "  ',',\n",
       "  'history',\n",
       "  ',',\n",
       "  'or',\n",
       "  'whatever',\n",
       "  'info',\n",
       "  'you',\n",
       "  'have',\n",
       "  'on',\n",
       "  'this',\n",
       "  'funky',\n",
       "  'looking',\n",
       "  'car',\n",
       "  ',',\n",
       "  'please',\n",
       "  'e-mail',\n",
       "  '.',\n",
       "  'thanks',\n",
       "  ',',\n",
       "  '-',\n",
       "  'il',\n",
       "  '--',\n",
       "  '--',\n",
       "  'brought',\n",
       "  'to',\n",
       "  'you',\n",
       "  'by',\n",
       "  'your',\n",
       "  'neighborhood',\n",
       "  'lerxst',\n",
       "  '--',\n",
       "  '--'],\n",
       " ['from',\n",
       "  ':',\n",
       "  'guykuo',\n",
       "  '@',\n",
       "  'carson.u.washington.edu',\n",
       "  '(',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  ')',\n",
       "  'subject',\n",
       "  ':',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'poll',\n",
       "  '-',\n",
       "  'final',\n",
       "  'call',\n",
       "  'summary',\n",
       "  ':',\n",
       "  'final',\n",
       "  'call',\n",
       "  'for',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'reports',\n",
       "  'keywords',\n",
       "  ':',\n",
       "  'si',\n",
       "  ',',\n",
       "  'acceleration',\n",
       "  ',',\n",
       "  'clock',\n",
       "  ',',\n",
       "  'upgrade',\n",
       "  'article-i.d',\n",
       "  '.',\n",
       "  ':',\n",
       "  'shelley.1qvfo9innc3s',\n",
       "  'organization',\n",
       "  ':',\n",
       "  'university',\n",
       "  'of',\n",
       "  'washington',\n",
       "  'lines',\n",
       "  ':',\n",
       "  '11',\n",
       "  'nntp-posting-host',\n",
       "  ':',\n",
       "  'carson.u.washington.edu',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'number',\n",
       "  'of',\n",
       "  'brave',\n",
       "  'souls',\n",
       "  'who',\n",
       "  'upgraded',\n",
       "  'their',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'oscillator',\n",
       "  'have',\n",
       "  'shared',\n",
       "  'their',\n",
       "  'experiences',\n",
       "  'for',\n",
       "  'this',\n",
       "  'poll',\n",
       "  '.',\n",
       "  'please',\n",
       "  'send',\n",
       "  'a',\n",
       "  'brief',\n",
       "  'message',\n",
       "  'detailing',\n",
       "  'your',\n",
       "  'experiences',\n",
       "  'with',\n",
       "  'the',\n",
       "  'procedure',\n",
       "  '.',\n",
       "  'top',\n",
       "  'speed',\n",
       "  'attained',\n",
       "  ',',\n",
       "  'cpu',\n",
       "  'rated',\n",
       "  'speed',\n",
       "  ',',\n",
       "  'add',\n",
       "  'on',\n",
       "  'cards',\n",
       "  'and',\n",
       "  'adapters',\n",
       "  ',',\n",
       "  'heat',\n",
       "  'sinks',\n",
       "  ',',\n",
       "  'hour',\n",
       "  'of',\n",
       "  'usage',\n",
       "  'per',\n",
       "  'day',\n",
       "  ',',\n",
       "  'floppy',\n",
       "  'disk',\n",
       "  'functionality',\n",
       "  'with',\n",
       "  '800',\n",
       "  'and',\n",
       "  '1.4',\n",
       "  'm',\n",
       "  'floppies',\n",
       "  'are',\n",
       "  'especially',\n",
       "  'requested',\n",
       "  '.',\n",
       "  'i',\n",
       "  'will',\n",
       "  'be',\n",
       "  'summarizing',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'two',\n",
       "  'days',\n",
       "  ',',\n",
       "  'so',\n",
       "  'please',\n",
       "  'add',\n",
       "  'to',\n",
       "  'the',\n",
       "  'network',\n",
       "  'knowledge',\n",
       "  'base',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'done',\n",
       "  'the',\n",
       "  'clock',\n",
       "  'upgrade',\n",
       "  'and',\n",
       "  'have',\n",
       "  \"n't\",\n",
       "  'answered',\n",
       "  'this',\n",
       "  'poll',\n",
       "  '.',\n",
       "  'thanks',\n",
       "  '.',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  '<',\n",
       "  'guykuo',\n",
       "  '@',\n",
       "  'u.washington.edu',\n",
       "  '>'],\n",
       " ['from',\n",
       "  ':',\n",
       "  'twillis',\n",
       "  '@',\n",
       "  'ec.ecn.purdue.edu',\n",
       "  '(',\n",
       "  'thomas',\n",
       "  'e',\n",
       "  'willis',\n",
       "  ')',\n",
       "  'subject',\n",
       "  ':',\n",
       "  'pb',\n",
       "  'questions',\n",
       "  '...',\n",
       "  'organization',\n",
       "  ':',\n",
       "  'purdue',\n",
       "  'university',\n",
       "  'engineering',\n",
       "  'computer',\n",
       "  'network',\n",
       "  'distribution',\n",
       "  ':',\n",
       "  'usa',\n",
       "  'lines',\n",
       "  ':',\n",
       "  '36',\n",
       "  'well',\n",
       "  'folks',\n",
       "  ',',\n",
       "  'my',\n",
       "  'mac',\n",
       "  'plus',\n",
       "  'finally',\n",
       "  'gave',\n",
       "  'up',\n",
       "  'the',\n",
       "  'ghost',\n",
       "  'this',\n",
       "  'weekend',\n",
       "  'after',\n",
       "  'starting',\n",
       "  'life',\n",
       "  'as',\n",
       "  'a',\n",
       "  '512k',\n",
       "  'way',\n",
       "  'back',\n",
       "  'in',\n",
       "  '1985.',\n",
       "  'sooo',\n",
       "  ',',\n",
       "  'i',\n",
       "  \"'m\",\n",
       "  'in',\n",
       "  'the',\n",
       "  'market',\n",
       "  'for',\n",
       "  'a',\n",
       "  'new',\n",
       "  'machine',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sooner',\n",
       "  'than',\n",
       "  'i',\n",
       "  'intended',\n",
       "  'to',\n",
       "  'be',\n",
       "  '...',\n",
       "  'i',\n",
       "  \"'m\",\n",
       "  'looking',\n",
       "  'into',\n",
       "  'picking',\n",
       "  'up',\n",
       "  'a',\n",
       "  'powerbook',\n",
       "  '160',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  '180',\n",
       "  'and',\n",
       "  'have',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'questions',\n",
       "  'that',\n",
       "  '(',\n",
       "  'hopefully',\n",
       "  ')',\n",
       "  'somebody',\n",
       "  'can',\n",
       "  'answer',\n",
       "  ':',\n",
       "  '*',\n",
       "  'does',\n",
       "  'anybody',\n",
       "  'know',\n",
       "  'any',\n",
       "  'dirt',\n",
       "  'on',\n",
       "  'when',\n",
       "  'the',\n",
       "  'next',\n",
       "  'round',\n",
       "  'of',\n",
       "  'powerbook',\n",
       "  'introductions',\n",
       "  'are',\n",
       "  'expected',\n",
       "  '?',\n",
       "  'i',\n",
       "  \"'d\",\n",
       "  'heard',\n",
       "  'the',\n",
       "  '185c',\n",
       "  'was',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'make',\n",
       "  'an',\n",
       "  'appearence',\n",
       "  '``',\n",
       "  'this',\n",
       "  'summer',\n",
       "  \"''\",\n",
       "  'but',\n",
       "  'have',\n",
       "  \"n't\",\n",
       "  'heard',\n",
       "  'anymore',\n",
       "  'on',\n",
       "  'it',\n",
       "  '-',\n",
       "  'and',\n",
       "  'since',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'access',\n",
       "  'to',\n",
       "  'macleak',\n",
       "  ',',\n",
       "  'i',\n",
       "  'was',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'anybody',\n",
       "  'out',\n",
       "  'there',\n",
       "  'had',\n",
       "  'more',\n",
       "  'info',\n",
       "  '...',\n",
       "  '*',\n",
       "  'has',\n",
       "  'anybody',\n",
       "  'heard',\n",
       "  'rumors',\n",
       "  'about',\n",
       "  'price',\n",
       "  'drops',\n",
       "  'to',\n",
       "  'the',\n",
       "  'powerbook',\n",
       "  'line',\n",
       "  'like',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'the',\n",
       "  'duo',\n",
       "  \"'s\",\n",
       "  'just',\n",
       "  'went',\n",
       "  'through',\n",
       "  'recently',\n",
       "  '?',\n",
       "  '*',\n",
       "  'what',\n",
       "  \"'s\",\n",
       "  'the',\n",
       "  'impression',\n",
       "  'of',\n",
       "  'the',\n",
       "  'display',\n",
       "  'on',\n",
       "  'the',\n",
       "  '180',\n",
       "  '?',\n",
       "  'i',\n",
       "  'could',\n",
       "  'probably',\n",
       "  'swing',\n",
       "  'a',\n",
       "  '180',\n",
       "  'if',\n",
       "  'i',\n",
       "  'got',\n",
       "  'the',\n",
       "  '80mb',\n",
       "  'disk',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'the',\n",
       "  '120',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'really',\n",
       "  'have',\n",
       "  'a',\n",
       "  'feel',\n",
       "  'for',\n",
       "  'how',\n",
       "  'much',\n",
       "  '``',\n",
       "  'better',\n",
       "  \"''\",\n",
       "  'the',\n",
       "  'display',\n",
       "  'is',\n",
       "  '(',\n",
       "  'yea',\n",
       "  ',',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'great',\n",
       "  'in',\n",
       "  'the',\n",
       "  'store',\n",
       "  ',',\n",
       "  'but',\n",
       "  'is',\n",
       "  'that',\n",
       "  'all',\n",
       "  '``',\n",
       "  'wow',\n",
       "  \"''\",\n",
       "  'or',\n",
       "  'is',\n",
       "  'it',\n",
       "  'really',\n",
       "  'that',\n",
       "  'good',\n",
       "  '?',\n",
       "  ')',\n",
       "  '.',\n",
       "  'could',\n",
       "  'i',\n",
       "  'solicit',\n",
       "  'some',\n",
       "  'opinions',\n",
       "  'of',\n",
       "  'people',\n",
       "  'who',\n",
       "  'use',\n",
       "  'the',\n",
       "  '160',\n",
       "  'and',\n",
       "  '180',\n",
       "  'day-to-day',\n",
       "  'on',\n",
       "  'if',\n",
       "  'its',\n",
       "  'worth',\n",
       "  'taking',\n",
       "  'the',\n",
       "  'disk',\n",
       "  'size',\n",
       "  'and',\n",
       "  'money',\n",
       "  'hit',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'active',\n",
       "  'display',\n",
       "  '?',\n",
       "  '(',\n",
       "  'i',\n",
       "  'realize',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'real',\n",
       "  'subjective',\n",
       "  'question',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  \"'ve\",\n",
       "  'only',\n",
       "  'played',\n",
       "  'around',\n",
       "  'with',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'in',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'store',\n",
       "  'breifly',\n",
       "  'and',\n",
       "  'figured',\n",
       "  'the',\n",
       "  'opinions',\n",
       "  'of',\n",
       "  'somebody',\n",
       "  'who',\n",
       "  'actually',\n",
       "  'uses',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'daily',\n",
       "  'might',\n",
       "  'prove',\n",
       "  'helpful',\n",
       "  ')',\n",
       "  '.',\n",
       "  '*',\n",
       "  'how',\n",
       "  'well',\n",
       "  'does',\n",
       "  'hellcats',\n",
       "  'perform',\n",
       "  '?',\n",
       "  ';',\n",
       "  ')',\n",
       "  'thanks',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'in',\n",
       "  'advance',\n",
       "  'for',\n",
       "  'any',\n",
       "  'info',\n",
       "  '-',\n",
       "  'if',\n",
       "  'you',\n",
       "  'could',\n",
       "  'email',\n",
       "  ',',\n",
       "  'i',\n",
       "  \"'ll\",\n",
       "  'post',\n",
       "  'a',\n",
       "  'summary',\n",
       "  '(',\n",
       "  'news',\n",
       "  'reading',\n",
       "  'time',\n",
       "  'is',\n",
       "  'at',\n",
       "  'a',\n",
       "  'premium',\n",
       "  'with',\n",
       "  'finals',\n",
       "  'just',\n",
       "  'around',\n",
       "  'the',\n",
       "  'corner',\n",
       "  '...',\n",
       "  ':',\n",
       "  '(',\n",
       "  ')',\n",
       "  '--',\n",
       "  'tom',\n",
       "  'willis',\n",
       "  '\\\\',\n",
       "  'twillis',\n",
       "  '@',\n",
       "  'ecn.purdue.edu',\n",
       "  '\\\\',\n",
       "  'purdue',\n",
       "  'electrical',\n",
       "  'engineering',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '--',\n",
       "  '-',\n",
       "  \"''\",\n",
       "  'convictions',\n",
       "  'are',\n",
       "  'more',\n",
       "  'dangerous',\n",
       "  'enemies',\n",
       "  'of',\n",
       "  'truth',\n",
       "  'than',\n",
       "  'lies',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  '-',\n",
       "  'f.',\n",
       "  'w.',\n",
       "  'nietzsche'],\n",
       " ['from',\n",
       "  ':',\n",
       "  'jgreen',\n",
       "  '@',\n",
       "  'amber',\n",
       "  '(',\n",
       "  'joe',\n",
       "  'green',\n",
       "  ')',\n",
       "  'subject',\n",
       "  ':',\n",
       "  're',\n",
       "  ':',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  '?',\n",
       "  'organization',\n",
       "  ':',\n",
       "  'harris',\n",
       "  'computer',\n",
       "  'systems',\n",
       "  'division',\n",
       "  'lines',\n",
       "  ':',\n",
       "  '14',\n",
       "  'distribution',\n",
       "  ':',\n",
       "  'world',\n",
       "  'nntp-posting-host',\n",
       "  ':',\n",
       "  'amber.ssd.csd.harris.com',\n",
       "  'x-newsreader',\n",
       "  ':',\n",
       "  'tin',\n",
       "  '[',\n",
       "  'version',\n",
       "  '1.1',\n",
       "  'pl9',\n",
       "  ']',\n",
       "  'robert',\n",
       "  'j.c.',\n",
       "  'kyanko',\n",
       "  '(',\n",
       "  'rob',\n",
       "  '@',\n",
       "  'rjck.uucp',\n",
       "  ')',\n",
       "  'wrote',\n",
       "  ':',\n",
       "  '>',\n",
       "  'abraxis',\n",
       "  '@',\n",
       "  'iastate.edu',\n",
       "  'writes',\n",
       "  'in',\n",
       "  'article',\n",
       "  '<',\n",
       "  'abraxis.734340159',\n",
       "  '@',\n",
       "  'class1.iastate.edu',\n",
       "  '>',\n",
       "  ':',\n",
       "  '>',\n",
       "  '>',\n",
       "  'anyone',\n",
       "  'know',\n",
       "  'about',\n",
       "  'the',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'graphics',\n",
       "  'chip',\n",
       "  '?',\n",
       "  '>',\n",
       "  'as',\n",
       "  'far',\n",
       "  'as',\n",
       "  'the',\n",
       "  'low-level',\n",
       "  'stuff',\n",
       "  'goes',\n",
       "  ',',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'pretty',\n",
       "  'nice',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'got',\n",
       "  'this',\n",
       "  '>',\n",
       "  'quadrilateral',\n",
       "  'fill',\n",
       "  'command',\n",
       "  'that',\n",
       "  'requires',\n",
       "  'just',\n",
       "  'the',\n",
       "  'four',\n",
       "  'points',\n",
       "  '.',\n",
       "  'do',\n",
       "  'you',\n",
       "  'have',\n",
       "  'weitek',\n",
       "  \"'s\",\n",
       "  'address/phone',\n",
       "  'number',\n",
       "  '?',\n",
       "  'i',\n",
       "  \"'d\",\n",
       "  'like',\n",
       "  'to',\n",
       "  'get',\n",
       "  'some',\n",
       "  'information',\n",
       "  'about',\n",
       "  'this',\n",
       "  'chip',\n",
       "  '.',\n",
       "  '--',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'harris',\n",
       "  'corporation',\n",
       "  'jgreen',\n",
       "  '@',\n",
       "  'csd.harris.com',\n",
       "  'computer',\n",
       "  'systems',\n",
       "  'division',\n",
       "  \"''\",\n",
       "  'the',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'that',\n",
       "  'really',\n",
       "  'scares',\n",
       "  'me',\n",
       "  'is',\n",
       "  'a',\n",
       "  'person',\n",
       "  'with',\n",
       "  'no',\n",
       "  'sense',\n",
       "  'of',\n",
       "  'humor',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  '--',\n",
       "  'jonathan',\n",
       "  'winters']]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing punctuations and extra expressions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import re\n",
    "cl3 = []\n",
    "for words in ct2:\n",
    "    c = []\n",
    "    for w in words:\n",
    "        res = re.sub(r'[^\\w\\s]',\"\",w)\n",
    "        if res != \"\":\n",
    "            c.append(res)\n",
    "    cl3.append(c)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cl3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['from',\n",
       "  'lerxst',\n",
       "  'wamumdedu',\n",
       "  'where',\n",
       "  's',\n",
       "  'my',\n",
       "  'thing',\n",
       "  'subject',\n",
       "  'what',\n",
       "  'car',\n",
       "  'is',\n",
       "  'this',\n",
       "  'nntppostinghost',\n",
       "  'rac3wamumdedu',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'of',\n",
       "  'maryland',\n",
       "  'college',\n",
       "  'park',\n",
       "  'lines',\n",
       "  '15',\n",
       "  'i',\n",
       "  'was',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'anyone',\n",
       "  'out',\n",
       "  'there',\n",
       "  'could',\n",
       "  'enlighten',\n",
       "  'me',\n",
       "  'on',\n",
       "  'this',\n",
       "  'car',\n",
       "  'i',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'other',\n",
       "  'day',\n",
       "  'it',\n",
       "  'was',\n",
       "  'a',\n",
       "  '2door',\n",
       "  'sports',\n",
       "  'car',\n",
       "  'looked',\n",
       "  'to',\n",
       "  'be',\n",
       "  'from',\n",
       "  'the',\n",
       "  'late',\n",
       "  '60s',\n",
       "  'early',\n",
       "  '70s',\n",
       "  'it',\n",
       "  'was',\n",
       "  'called',\n",
       "  'a',\n",
       "  'bricklin',\n",
       "  'the',\n",
       "  'doors',\n",
       "  'were',\n",
       "  'really',\n",
       "  'small',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'the',\n",
       "  'front',\n",
       "  'bumper',\n",
       "  'was',\n",
       "  'separate',\n",
       "  'from',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'body',\n",
       "  'this',\n",
       "  'is',\n",
       "  'all',\n",
       "  'i',\n",
       "  'know',\n",
       "  'if',\n",
       "  'anyone',\n",
       "  'can',\n",
       "  'tellme',\n",
       "  'a',\n",
       "  'model',\n",
       "  'name',\n",
       "  'engine',\n",
       "  'specs',\n",
       "  'years',\n",
       "  'of',\n",
       "  'production',\n",
       "  'where',\n",
       "  'this',\n",
       "  'car',\n",
       "  'is',\n",
       "  'made',\n",
       "  'history',\n",
       "  'or',\n",
       "  'whatever',\n",
       "  'info',\n",
       "  'you',\n",
       "  'have',\n",
       "  'on',\n",
       "  'this',\n",
       "  'funky',\n",
       "  'looking',\n",
       "  'car',\n",
       "  'please',\n",
       "  'email',\n",
       "  'thanks',\n",
       "  'il',\n",
       "  'brought',\n",
       "  'to',\n",
       "  'you',\n",
       "  'by',\n",
       "  'your',\n",
       "  'neighborhood',\n",
       "  'lerxst'],\n",
       " ['from',\n",
       "  'guykuo',\n",
       "  'carsonuwashingtonedu',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'subject',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'poll',\n",
       "  'final',\n",
       "  'call',\n",
       "  'summary',\n",
       "  'final',\n",
       "  'call',\n",
       "  'for',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'reports',\n",
       "  'keywords',\n",
       "  'si',\n",
       "  'acceleration',\n",
       "  'clock',\n",
       "  'upgrade',\n",
       "  'articleid',\n",
       "  'shelley1qvfo9innc3s',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'of',\n",
       "  'washington',\n",
       "  'lines',\n",
       "  '11',\n",
       "  'nntppostinghost',\n",
       "  'carsonuwashingtonedu',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'number',\n",
       "  'of',\n",
       "  'brave',\n",
       "  'souls',\n",
       "  'who',\n",
       "  'upgraded',\n",
       "  'their',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'oscillator',\n",
       "  'have',\n",
       "  'shared',\n",
       "  'their',\n",
       "  'experiences',\n",
       "  'for',\n",
       "  'this',\n",
       "  'poll',\n",
       "  'please',\n",
       "  'send',\n",
       "  'a',\n",
       "  'brief',\n",
       "  'message',\n",
       "  'detailing',\n",
       "  'your',\n",
       "  'experiences',\n",
       "  'with',\n",
       "  'the',\n",
       "  'procedure',\n",
       "  'top',\n",
       "  'speed',\n",
       "  'attained',\n",
       "  'cpu',\n",
       "  'rated',\n",
       "  'speed',\n",
       "  'add',\n",
       "  'on',\n",
       "  'cards',\n",
       "  'and',\n",
       "  'adapters',\n",
       "  'heat',\n",
       "  'sinks',\n",
       "  'hour',\n",
       "  'of',\n",
       "  'usage',\n",
       "  'per',\n",
       "  'day',\n",
       "  'floppy',\n",
       "  'disk',\n",
       "  'functionality',\n",
       "  'with',\n",
       "  '800',\n",
       "  'and',\n",
       "  '14',\n",
       "  'm',\n",
       "  'floppies',\n",
       "  'are',\n",
       "  'especially',\n",
       "  'requested',\n",
       "  'i',\n",
       "  'will',\n",
       "  'be',\n",
       "  'summarizing',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'two',\n",
       "  'days',\n",
       "  'so',\n",
       "  'please',\n",
       "  'add',\n",
       "  'to',\n",
       "  'the',\n",
       "  'network',\n",
       "  'knowledge',\n",
       "  'base',\n",
       "  'if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'done',\n",
       "  'the',\n",
       "  'clock',\n",
       "  'upgrade',\n",
       "  'and',\n",
       "  'have',\n",
       "  'nt',\n",
       "  'answered',\n",
       "  'this',\n",
       "  'poll',\n",
       "  'thanks',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'guykuo',\n",
       "  'uwashingtonedu'],\n",
       " ['from',\n",
       "  'twillis',\n",
       "  'ececnpurdueedu',\n",
       "  'thomas',\n",
       "  'e',\n",
       "  'willis',\n",
       "  'subject',\n",
       "  'pb',\n",
       "  'questions',\n",
       "  'organization',\n",
       "  'purdue',\n",
       "  'university',\n",
       "  'engineering',\n",
       "  'computer',\n",
       "  'network',\n",
       "  'distribution',\n",
       "  'usa',\n",
       "  'lines',\n",
       "  '36',\n",
       "  'well',\n",
       "  'folks',\n",
       "  'my',\n",
       "  'mac',\n",
       "  'plus',\n",
       "  'finally',\n",
       "  'gave',\n",
       "  'up',\n",
       "  'the',\n",
       "  'ghost',\n",
       "  'this',\n",
       "  'weekend',\n",
       "  'after',\n",
       "  'starting',\n",
       "  'life',\n",
       "  'as',\n",
       "  'a',\n",
       "  '512k',\n",
       "  'way',\n",
       "  'back',\n",
       "  'in',\n",
       "  '1985',\n",
       "  'sooo',\n",
       "  'i',\n",
       "  'm',\n",
       "  'in',\n",
       "  'the',\n",
       "  'market',\n",
       "  'for',\n",
       "  'a',\n",
       "  'new',\n",
       "  'machine',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sooner',\n",
       "  'than',\n",
       "  'i',\n",
       "  'intended',\n",
       "  'to',\n",
       "  'be',\n",
       "  'i',\n",
       "  'm',\n",
       "  'looking',\n",
       "  'into',\n",
       "  'picking',\n",
       "  'up',\n",
       "  'a',\n",
       "  'powerbook',\n",
       "  '160',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  '180',\n",
       "  'and',\n",
       "  'have',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'questions',\n",
       "  'that',\n",
       "  'hopefully',\n",
       "  'somebody',\n",
       "  'can',\n",
       "  'answer',\n",
       "  'does',\n",
       "  'anybody',\n",
       "  'know',\n",
       "  'any',\n",
       "  'dirt',\n",
       "  'on',\n",
       "  'when',\n",
       "  'the',\n",
       "  'next',\n",
       "  'round',\n",
       "  'of',\n",
       "  'powerbook',\n",
       "  'introductions',\n",
       "  'are',\n",
       "  'expected',\n",
       "  'i',\n",
       "  'd',\n",
       "  'heard',\n",
       "  'the',\n",
       "  '185c',\n",
       "  'was',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'make',\n",
       "  'an',\n",
       "  'appearence',\n",
       "  'this',\n",
       "  'summer',\n",
       "  'but',\n",
       "  'have',\n",
       "  'nt',\n",
       "  'heard',\n",
       "  'anymore',\n",
       "  'on',\n",
       "  'it',\n",
       "  'and',\n",
       "  'since',\n",
       "  'i',\n",
       "  'do',\n",
       "  'nt',\n",
       "  'have',\n",
       "  'access',\n",
       "  'to',\n",
       "  'macleak',\n",
       "  'i',\n",
       "  'was',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'anybody',\n",
       "  'out',\n",
       "  'there',\n",
       "  'had',\n",
       "  'more',\n",
       "  'info',\n",
       "  'has',\n",
       "  'anybody',\n",
       "  'heard',\n",
       "  'rumors',\n",
       "  'about',\n",
       "  'price',\n",
       "  'drops',\n",
       "  'to',\n",
       "  'the',\n",
       "  'powerbook',\n",
       "  'line',\n",
       "  'like',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'the',\n",
       "  'duo',\n",
       "  's',\n",
       "  'just',\n",
       "  'went',\n",
       "  'through',\n",
       "  'recently',\n",
       "  'what',\n",
       "  's',\n",
       "  'the',\n",
       "  'impression',\n",
       "  'of',\n",
       "  'the',\n",
       "  'display',\n",
       "  'on',\n",
       "  'the',\n",
       "  '180',\n",
       "  'i',\n",
       "  'could',\n",
       "  'probably',\n",
       "  'swing',\n",
       "  'a',\n",
       "  '180',\n",
       "  'if',\n",
       "  'i',\n",
       "  'got',\n",
       "  'the',\n",
       "  '80mb',\n",
       "  'disk',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'the',\n",
       "  '120',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  'nt',\n",
       "  'really',\n",
       "  'have',\n",
       "  'a',\n",
       "  'feel',\n",
       "  'for',\n",
       "  'how',\n",
       "  'much',\n",
       "  'better',\n",
       "  'the',\n",
       "  'display',\n",
       "  'is',\n",
       "  'yea',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'great',\n",
       "  'in',\n",
       "  'the',\n",
       "  'store',\n",
       "  'but',\n",
       "  'is',\n",
       "  'that',\n",
       "  'all',\n",
       "  'wow',\n",
       "  'or',\n",
       "  'is',\n",
       "  'it',\n",
       "  'really',\n",
       "  'that',\n",
       "  'good',\n",
       "  'could',\n",
       "  'i',\n",
       "  'solicit',\n",
       "  'some',\n",
       "  'opinions',\n",
       "  'of',\n",
       "  'people',\n",
       "  'who',\n",
       "  'use',\n",
       "  'the',\n",
       "  '160',\n",
       "  'and',\n",
       "  '180',\n",
       "  'daytoday',\n",
       "  'on',\n",
       "  'if',\n",
       "  'its',\n",
       "  'worth',\n",
       "  'taking',\n",
       "  'the',\n",
       "  'disk',\n",
       "  'size',\n",
       "  'and',\n",
       "  'money',\n",
       "  'hit',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'active',\n",
       "  'display',\n",
       "  'i',\n",
       "  'realize',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'real',\n",
       "  'subjective',\n",
       "  'question',\n",
       "  'but',\n",
       "  'i',\n",
       "  've',\n",
       "  'only',\n",
       "  'played',\n",
       "  'around',\n",
       "  'with',\n",
       "  'the',\n",
       "  'machines',\n",
       "  'in',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'store',\n",
       "  'breifly',\n",
       "  'and',\n",
       "  'figured',\n",
       "  'the',\n",
       "  'opinions',\n",
       "  'of',\n",
       "  'somebody',\n",
       "  'who',\n",
       "  'actually',\n",
       "  'uses',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'daily',\n",
       "  'might',\n",
       "  'prove',\n",
       "  'helpful',\n",
       "  'how',\n",
       "  'well',\n",
       "  'does',\n",
       "  'hellcats',\n",
       "  'perform',\n",
       "  'thanks',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'in',\n",
       "  'advance',\n",
       "  'for',\n",
       "  'any',\n",
       "  'info',\n",
       "  'if',\n",
       "  'you',\n",
       "  'could',\n",
       "  'email',\n",
       "  'i',\n",
       "  'll',\n",
       "  'post',\n",
       "  'a',\n",
       "  'summary',\n",
       "  'news',\n",
       "  'reading',\n",
       "  'time',\n",
       "  'is',\n",
       "  'at',\n",
       "  'a',\n",
       "  'premium',\n",
       "  'with',\n",
       "  'finals',\n",
       "  'just',\n",
       "  'around',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'tom',\n",
       "  'willis',\n",
       "  'twillis',\n",
       "  'ecnpurdueedu',\n",
       "  'purdue',\n",
       "  'electrical',\n",
       "  'engineering',\n",
       "  'convictions',\n",
       "  'are',\n",
       "  'more',\n",
       "  'dangerous',\n",
       "  'enemies',\n",
       "  'of',\n",
       "  'truth',\n",
       "  'than',\n",
       "  'lies',\n",
       "  'f',\n",
       "  'w',\n",
       "  'nietzsche'],\n",
       " ['from',\n",
       "  'jgreen',\n",
       "  'amber',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'subject',\n",
       "  're',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'organization',\n",
       "  'harris',\n",
       "  'computer',\n",
       "  'systems',\n",
       "  'division',\n",
       "  'lines',\n",
       "  '14',\n",
       "  'distribution',\n",
       "  'world',\n",
       "  'nntppostinghost',\n",
       "  'amberssdcsdharriscom',\n",
       "  'xnewsreader',\n",
       "  'tin',\n",
       "  'version',\n",
       "  '11',\n",
       "  'pl9',\n",
       "  'robert',\n",
       "  'jc',\n",
       "  'kyanko',\n",
       "  'rob',\n",
       "  'rjckuucp',\n",
       "  'wrote',\n",
       "  'abraxis',\n",
       "  'iastateedu',\n",
       "  'writes',\n",
       "  'in',\n",
       "  'article',\n",
       "  'abraxis734340159',\n",
       "  'class1iastateedu',\n",
       "  'anyone',\n",
       "  'know',\n",
       "  'about',\n",
       "  'the',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'graphics',\n",
       "  'chip',\n",
       "  'as',\n",
       "  'far',\n",
       "  'as',\n",
       "  'the',\n",
       "  'lowlevel',\n",
       "  'stuff',\n",
       "  'goes',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'pretty',\n",
       "  'nice',\n",
       "  'it',\n",
       "  's',\n",
       "  'got',\n",
       "  'this',\n",
       "  'quadrilateral',\n",
       "  'fill',\n",
       "  'command',\n",
       "  'that',\n",
       "  'requires',\n",
       "  'just',\n",
       "  'the',\n",
       "  'four',\n",
       "  'points',\n",
       "  'do',\n",
       "  'you',\n",
       "  'have',\n",
       "  'weitek',\n",
       "  's',\n",
       "  'addressphone',\n",
       "  'number',\n",
       "  'i',\n",
       "  'd',\n",
       "  'like',\n",
       "  'to',\n",
       "  'get',\n",
       "  'some',\n",
       "  'information',\n",
       "  'about',\n",
       "  'this',\n",
       "  'chip',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'harris',\n",
       "  'corporation',\n",
       "  'jgreen',\n",
       "  'csdharriscom',\n",
       "  'computer',\n",
       "  'systems',\n",
       "  'division',\n",
       "  'the',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'that',\n",
       "  'really',\n",
       "  'scares',\n",
       "  'me',\n",
       "  'is',\n",
       "  'a',\n",
       "  'person',\n",
       "  'with',\n",
       "  'no',\n",
       "  'sense',\n",
       "  'of',\n",
       "  'humor',\n",
       "  'jonathan',\n",
       "  'winters']]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "nl.download('stopwords')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prajualpillai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cl4 = []\n",
    "for words in cl3:\n",
    "    w = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            w.append(word)\n",
    "    cl4.append(w)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "cl4"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['lerxst',\n",
       "  'wamumdedu',\n",
       "  'thing',\n",
       "  'subject',\n",
       "  'car',\n",
       "  'nntppostinghost',\n",
       "  'rac3wamumdedu',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'maryland',\n",
       "  'college',\n",
       "  'park',\n",
       "  'lines',\n",
       "  '15',\n",
       "  'wondering',\n",
       "  'anyone',\n",
       "  'could',\n",
       "  'enlighten',\n",
       "  'car',\n",
       "  'saw',\n",
       "  'day',\n",
       "  '2door',\n",
       "  'sports',\n",
       "  'car',\n",
       "  'looked',\n",
       "  'late',\n",
       "  '60s',\n",
       "  'early',\n",
       "  '70s',\n",
       "  'called',\n",
       "  'bricklin',\n",
       "  'doors',\n",
       "  'really',\n",
       "  'small',\n",
       "  'addition',\n",
       "  'front',\n",
       "  'bumper',\n",
       "  'separate',\n",
       "  'rest',\n",
       "  'body',\n",
       "  'know',\n",
       "  'anyone',\n",
       "  'tellme',\n",
       "  'model',\n",
       "  'name',\n",
       "  'engine',\n",
       "  'specs',\n",
       "  'years',\n",
       "  'production',\n",
       "  'car',\n",
       "  'made',\n",
       "  'history',\n",
       "  'whatever',\n",
       "  'info',\n",
       "  'funky',\n",
       "  'looking',\n",
       "  'car',\n",
       "  'please',\n",
       "  'email',\n",
       "  'thanks',\n",
       "  'il',\n",
       "  'brought',\n",
       "  'neighborhood',\n",
       "  'lerxst'],\n",
       " ['guykuo',\n",
       "  'carsonuwashingtonedu',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'subject',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'poll',\n",
       "  'final',\n",
       "  'call',\n",
       "  'summary',\n",
       "  'final',\n",
       "  'call',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'reports',\n",
       "  'keywords',\n",
       "  'si',\n",
       "  'acceleration',\n",
       "  'clock',\n",
       "  'upgrade',\n",
       "  'articleid',\n",
       "  'shelley1qvfo9innc3s',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'washington',\n",
       "  'lines',\n",
       "  '11',\n",
       "  'nntppostinghost',\n",
       "  'carsonuwashingtonedu',\n",
       "  'fair',\n",
       "  'number',\n",
       "  'brave',\n",
       "  'souls',\n",
       "  'upgraded',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'oscillator',\n",
       "  'shared',\n",
       "  'experiences',\n",
       "  'poll',\n",
       "  'please',\n",
       "  'send',\n",
       "  'brief',\n",
       "  'message',\n",
       "  'detailing',\n",
       "  'experiences',\n",
       "  'procedure',\n",
       "  'top',\n",
       "  'speed',\n",
       "  'attained',\n",
       "  'cpu',\n",
       "  'rated',\n",
       "  'speed',\n",
       "  'add',\n",
       "  'cards',\n",
       "  'adapters',\n",
       "  'heat',\n",
       "  'sinks',\n",
       "  'hour',\n",
       "  'usage',\n",
       "  'per',\n",
       "  'day',\n",
       "  'floppy',\n",
       "  'disk',\n",
       "  'functionality',\n",
       "  '800',\n",
       "  '14',\n",
       "  'floppies',\n",
       "  'especially',\n",
       "  'requested',\n",
       "  'summarizing',\n",
       "  'next',\n",
       "  'two',\n",
       "  'days',\n",
       "  'please',\n",
       "  'add',\n",
       "  'network',\n",
       "  'knowledge',\n",
       "  'base',\n",
       "  'done',\n",
       "  'clock',\n",
       "  'upgrade',\n",
       "  'nt',\n",
       "  'answered',\n",
       "  'poll',\n",
       "  'thanks',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'guykuo',\n",
       "  'uwashingtonedu'],\n",
       " ['twillis',\n",
       "  'ececnpurdueedu',\n",
       "  'thomas',\n",
       "  'e',\n",
       "  'willis',\n",
       "  'subject',\n",
       "  'pb',\n",
       "  'questions',\n",
       "  'organization',\n",
       "  'purdue',\n",
       "  'university',\n",
       "  'engineering',\n",
       "  'computer',\n",
       "  'network',\n",
       "  'distribution',\n",
       "  'usa',\n",
       "  'lines',\n",
       "  '36',\n",
       "  'well',\n",
       "  'folks',\n",
       "  'mac',\n",
       "  'plus',\n",
       "  'finally',\n",
       "  'gave',\n",
       "  'ghost',\n",
       "  'weekend',\n",
       "  'starting',\n",
       "  'life',\n",
       "  '512k',\n",
       "  'way',\n",
       "  'back',\n",
       "  '1985',\n",
       "  'sooo',\n",
       "  'market',\n",
       "  'new',\n",
       "  'machine',\n",
       "  'bit',\n",
       "  'sooner',\n",
       "  'intended',\n",
       "  'looking',\n",
       "  'picking',\n",
       "  'powerbook',\n",
       "  '160',\n",
       "  'maybe',\n",
       "  '180',\n",
       "  'bunch',\n",
       "  'questions',\n",
       "  'hopefully',\n",
       "  'somebody',\n",
       "  'answer',\n",
       "  'anybody',\n",
       "  'know',\n",
       "  'dirt',\n",
       "  'next',\n",
       "  'round',\n",
       "  'powerbook',\n",
       "  'introductions',\n",
       "  'expected',\n",
       "  'heard',\n",
       "  '185c',\n",
       "  'supposed',\n",
       "  'make',\n",
       "  'appearence',\n",
       "  'summer',\n",
       "  'nt',\n",
       "  'heard',\n",
       "  'anymore',\n",
       "  'since',\n",
       "  'nt',\n",
       "  'access',\n",
       "  'macleak',\n",
       "  'wondering',\n",
       "  'anybody',\n",
       "  'info',\n",
       "  'anybody',\n",
       "  'heard',\n",
       "  'rumors',\n",
       "  'price',\n",
       "  'drops',\n",
       "  'powerbook',\n",
       "  'line',\n",
       "  'like',\n",
       "  'ones',\n",
       "  'duo',\n",
       "  'went',\n",
       "  'recently',\n",
       "  'impression',\n",
       "  'display',\n",
       "  '180',\n",
       "  'could',\n",
       "  'probably',\n",
       "  'swing',\n",
       "  '180',\n",
       "  'got',\n",
       "  '80mb',\n",
       "  'disk',\n",
       "  'rather',\n",
       "  '120',\n",
       "  'nt',\n",
       "  'really',\n",
       "  'feel',\n",
       "  'much',\n",
       "  'better',\n",
       "  'display',\n",
       "  'yea',\n",
       "  'looks',\n",
       "  'great',\n",
       "  'store',\n",
       "  'wow',\n",
       "  'really',\n",
       "  'good',\n",
       "  'could',\n",
       "  'solicit',\n",
       "  'opinions',\n",
       "  'people',\n",
       "  'use',\n",
       "  '160',\n",
       "  '180',\n",
       "  'daytoday',\n",
       "  'worth',\n",
       "  'taking',\n",
       "  'disk',\n",
       "  'size',\n",
       "  'money',\n",
       "  'hit',\n",
       "  'get',\n",
       "  'active',\n",
       "  'display',\n",
       "  'realize',\n",
       "  'real',\n",
       "  'subjective',\n",
       "  'question',\n",
       "  'played',\n",
       "  'around',\n",
       "  'machines',\n",
       "  'computer',\n",
       "  'store',\n",
       "  'breifly',\n",
       "  'figured',\n",
       "  'opinions',\n",
       "  'somebody',\n",
       "  'actually',\n",
       "  'uses',\n",
       "  'machine',\n",
       "  'daily',\n",
       "  'might',\n",
       "  'prove',\n",
       "  'helpful',\n",
       "  'well',\n",
       "  'hellcats',\n",
       "  'perform',\n",
       "  'thanks',\n",
       "  'bunch',\n",
       "  'advance',\n",
       "  'info',\n",
       "  'could',\n",
       "  'email',\n",
       "  'post',\n",
       "  'summary',\n",
       "  'news',\n",
       "  'reading',\n",
       "  'time',\n",
       "  'premium',\n",
       "  'finals',\n",
       "  'around',\n",
       "  'corner',\n",
       "  'tom',\n",
       "  'willis',\n",
       "  'twillis',\n",
       "  'ecnpurdueedu',\n",
       "  'purdue',\n",
       "  'electrical',\n",
       "  'engineering',\n",
       "  'convictions',\n",
       "  'dangerous',\n",
       "  'enemies',\n",
       "  'truth',\n",
       "  'lies',\n",
       "  'f',\n",
       "  'w',\n",
       "  'nietzsche'],\n",
       " ['jgreen',\n",
       "  'amber',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'subject',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'organization',\n",
       "  'harris',\n",
       "  'computer',\n",
       "  'systems',\n",
       "  'division',\n",
       "  'lines',\n",
       "  '14',\n",
       "  'distribution',\n",
       "  'world',\n",
       "  'nntppostinghost',\n",
       "  'amberssdcsdharriscom',\n",
       "  'xnewsreader',\n",
       "  'tin',\n",
       "  'version',\n",
       "  '11',\n",
       "  'pl9',\n",
       "  'robert',\n",
       "  'jc',\n",
       "  'kyanko',\n",
       "  'rob',\n",
       "  'rjckuucp',\n",
       "  'wrote',\n",
       "  'abraxis',\n",
       "  'iastateedu',\n",
       "  'writes',\n",
       "  'article',\n",
       "  'abraxis734340159',\n",
       "  'class1iastateedu',\n",
       "  'anyone',\n",
       "  'know',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'graphics',\n",
       "  'chip',\n",
       "  'far',\n",
       "  'lowlevel',\n",
       "  'stuff',\n",
       "  'goes',\n",
       "  'looks',\n",
       "  'pretty',\n",
       "  'nice',\n",
       "  'got',\n",
       "  'quadrilateral',\n",
       "  'fill',\n",
       "  'command',\n",
       "  'requires',\n",
       "  'four',\n",
       "  'points',\n",
       "  'weitek',\n",
       "  'addressphone',\n",
       "  'number',\n",
       "  'like',\n",
       "  'get',\n",
       "  'information',\n",
       "  'chip',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'harris',\n",
       "  'corporation',\n",
       "  'jgreen',\n",
       "  'csdharriscom',\n",
       "  'computer',\n",
       "  'systems',\n",
       "  'division',\n",
       "  'thing',\n",
       "  'really',\n",
       "  'scares',\n",
       "  'person',\n",
       "  'sense',\n",
       "  'humor',\n",
       "  'jonathan',\n",
       "  'winters']]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stemming"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "port = PorterStemmer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "a = [port.stem(i) for i in ['reading','wash','tilts']]\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['read', 'wash', 'tilt']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "cl5 = []\n",
    "for words in cl4:\n",
    "    w = []\n",
    "    for word in words:\n",
    "        w.append(port.stem(word))\n",
    "    cl5.append(w)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cl5"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['lerxst',\n",
       "  'wamumdedu',\n",
       "  'thing',\n",
       "  'subject',\n",
       "  'car',\n",
       "  'nntppostinghost',\n",
       "  'rac3wamumdedu',\n",
       "  'organ',\n",
       "  'univers',\n",
       "  'maryland',\n",
       "  'colleg',\n",
       "  'park',\n",
       "  'line',\n",
       "  '15',\n",
       "  'wonder',\n",
       "  'anyon',\n",
       "  'could',\n",
       "  'enlighten',\n",
       "  'car',\n",
       "  'saw',\n",
       "  'day',\n",
       "  '2door',\n",
       "  'sport',\n",
       "  'car',\n",
       "  'look',\n",
       "  'late',\n",
       "  '60',\n",
       "  'earli',\n",
       "  '70',\n",
       "  'call',\n",
       "  'bricklin',\n",
       "  'door',\n",
       "  'realli',\n",
       "  'small',\n",
       "  'addit',\n",
       "  'front',\n",
       "  'bumper',\n",
       "  'separ',\n",
       "  'rest',\n",
       "  'bodi',\n",
       "  'know',\n",
       "  'anyon',\n",
       "  'tellm',\n",
       "  'model',\n",
       "  'name',\n",
       "  'engin',\n",
       "  'spec',\n",
       "  'year',\n",
       "  'product',\n",
       "  'car',\n",
       "  'made',\n",
       "  'histori',\n",
       "  'whatev',\n",
       "  'info',\n",
       "  'funki',\n",
       "  'look',\n",
       "  'car',\n",
       "  'pleas',\n",
       "  'email',\n",
       "  'thank',\n",
       "  'il',\n",
       "  'brought',\n",
       "  'neighborhood',\n",
       "  'lerxst'],\n",
       " ['guykuo',\n",
       "  'carsonuwashingtonedu',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'subject',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'poll',\n",
       "  'final',\n",
       "  'call',\n",
       "  'summari',\n",
       "  'final',\n",
       "  'call',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'report',\n",
       "  'keyword',\n",
       "  'si',\n",
       "  'acceler',\n",
       "  'clock',\n",
       "  'upgrad',\n",
       "  'articleid',\n",
       "  'shelley1qvfo9innc3',\n",
       "  'organ',\n",
       "  'univers',\n",
       "  'washington',\n",
       "  'line',\n",
       "  '11',\n",
       "  'nntppostinghost',\n",
       "  'carsonuwashingtonedu',\n",
       "  'fair',\n",
       "  'number',\n",
       "  'brave',\n",
       "  'soul',\n",
       "  'upgrad',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'oscil',\n",
       "  'share',\n",
       "  'experi',\n",
       "  'poll',\n",
       "  'pleas',\n",
       "  'send',\n",
       "  'brief',\n",
       "  'messag',\n",
       "  'detail',\n",
       "  'experi',\n",
       "  'procedur',\n",
       "  'top',\n",
       "  'speed',\n",
       "  'attain',\n",
       "  'cpu',\n",
       "  'rate',\n",
       "  'speed',\n",
       "  'add',\n",
       "  'card',\n",
       "  'adapt',\n",
       "  'heat',\n",
       "  'sink',\n",
       "  'hour',\n",
       "  'usag',\n",
       "  'per',\n",
       "  'day',\n",
       "  'floppi',\n",
       "  'disk',\n",
       "  'function',\n",
       "  '800',\n",
       "  '14',\n",
       "  'floppi',\n",
       "  'especi',\n",
       "  'request',\n",
       "  'summar',\n",
       "  'next',\n",
       "  'two',\n",
       "  'day',\n",
       "  'pleas',\n",
       "  'add',\n",
       "  'network',\n",
       "  'knowledg',\n",
       "  'base',\n",
       "  'done',\n",
       "  'clock',\n",
       "  'upgrad',\n",
       "  'nt',\n",
       "  'answer',\n",
       "  'poll',\n",
       "  'thank',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'guykuo',\n",
       "  'uwashingtonedu'],\n",
       " ['twilli',\n",
       "  'ececnpurdueedu',\n",
       "  'thoma',\n",
       "  'e',\n",
       "  'willi',\n",
       "  'subject',\n",
       "  'pb',\n",
       "  'question',\n",
       "  'organ',\n",
       "  'purdu',\n",
       "  'univers',\n",
       "  'engin',\n",
       "  'comput',\n",
       "  'network',\n",
       "  'distribut',\n",
       "  'usa',\n",
       "  'line',\n",
       "  '36',\n",
       "  'well',\n",
       "  'folk',\n",
       "  'mac',\n",
       "  'plu',\n",
       "  'final',\n",
       "  'gave',\n",
       "  'ghost',\n",
       "  'weekend',\n",
       "  'start',\n",
       "  'life',\n",
       "  '512k',\n",
       "  'way',\n",
       "  'back',\n",
       "  '1985',\n",
       "  'sooo',\n",
       "  'market',\n",
       "  'new',\n",
       "  'machin',\n",
       "  'bit',\n",
       "  'sooner',\n",
       "  'intend',\n",
       "  'look',\n",
       "  'pick',\n",
       "  'powerbook',\n",
       "  '160',\n",
       "  'mayb',\n",
       "  '180',\n",
       "  'bunch',\n",
       "  'question',\n",
       "  'hope',\n",
       "  'somebodi',\n",
       "  'answer',\n",
       "  'anybodi',\n",
       "  'know',\n",
       "  'dirt',\n",
       "  'next',\n",
       "  'round',\n",
       "  'powerbook',\n",
       "  'introduct',\n",
       "  'expect',\n",
       "  'heard',\n",
       "  '185c',\n",
       "  'suppos',\n",
       "  'make',\n",
       "  'appear',\n",
       "  'summer',\n",
       "  'nt',\n",
       "  'heard',\n",
       "  'anymor',\n",
       "  'sinc',\n",
       "  'nt',\n",
       "  'access',\n",
       "  'macleak',\n",
       "  'wonder',\n",
       "  'anybodi',\n",
       "  'info',\n",
       "  'anybodi',\n",
       "  'heard',\n",
       "  'rumor',\n",
       "  'price',\n",
       "  'drop',\n",
       "  'powerbook',\n",
       "  'line',\n",
       "  'like',\n",
       "  'one',\n",
       "  'duo',\n",
       "  'went',\n",
       "  'recent',\n",
       "  'impress',\n",
       "  'display',\n",
       "  '180',\n",
       "  'could',\n",
       "  'probabl',\n",
       "  'swing',\n",
       "  '180',\n",
       "  'got',\n",
       "  '80mb',\n",
       "  'disk',\n",
       "  'rather',\n",
       "  '120',\n",
       "  'nt',\n",
       "  'realli',\n",
       "  'feel',\n",
       "  'much',\n",
       "  'better',\n",
       "  'display',\n",
       "  'yea',\n",
       "  'look',\n",
       "  'great',\n",
       "  'store',\n",
       "  'wow',\n",
       "  'realli',\n",
       "  'good',\n",
       "  'could',\n",
       "  'solicit',\n",
       "  'opinion',\n",
       "  'peopl',\n",
       "  'use',\n",
       "  '160',\n",
       "  '180',\n",
       "  'daytoday',\n",
       "  'worth',\n",
       "  'take',\n",
       "  'disk',\n",
       "  'size',\n",
       "  'money',\n",
       "  'hit',\n",
       "  'get',\n",
       "  'activ',\n",
       "  'display',\n",
       "  'realiz',\n",
       "  'real',\n",
       "  'subject',\n",
       "  'question',\n",
       "  'play',\n",
       "  'around',\n",
       "  'machin',\n",
       "  'comput',\n",
       "  'store',\n",
       "  'breifli',\n",
       "  'figur',\n",
       "  'opinion',\n",
       "  'somebodi',\n",
       "  'actual',\n",
       "  'use',\n",
       "  'machin',\n",
       "  'daili',\n",
       "  'might',\n",
       "  'prove',\n",
       "  'help',\n",
       "  'well',\n",
       "  'hellcat',\n",
       "  'perform',\n",
       "  'thank',\n",
       "  'bunch',\n",
       "  'advanc',\n",
       "  'info',\n",
       "  'could',\n",
       "  'email',\n",
       "  'post',\n",
       "  'summari',\n",
       "  'news',\n",
       "  'read',\n",
       "  'time',\n",
       "  'premium',\n",
       "  'final',\n",
       "  'around',\n",
       "  'corner',\n",
       "  'tom',\n",
       "  'willi',\n",
       "  'twilli',\n",
       "  'ecnpurdueedu',\n",
       "  'purdu',\n",
       "  'electr',\n",
       "  'engin',\n",
       "  'convict',\n",
       "  'danger',\n",
       "  'enemi',\n",
       "  'truth',\n",
       "  'lie',\n",
       "  'f',\n",
       "  'w',\n",
       "  'nietzsch'],\n",
       " ['jgreen',\n",
       "  'amber',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'subject',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'organ',\n",
       "  'harri',\n",
       "  'comput',\n",
       "  'system',\n",
       "  'divis',\n",
       "  'line',\n",
       "  '14',\n",
       "  'distribut',\n",
       "  'world',\n",
       "  'nntppostinghost',\n",
       "  'amberssdcsdharriscom',\n",
       "  'xnewsread',\n",
       "  'tin',\n",
       "  'version',\n",
       "  '11',\n",
       "  'pl9',\n",
       "  'robert',\n",
       "  'jc',\n",
       "  'kyanko',\n",
       "  'rob',\n",
       "  'rjckuucp',\n",
       "  'wrote',\n",
       "  'abraxi',\n",
       "  'iastateedu',\n",
       "  'write',\n",
       "  'articl',\n",
       "  'abraxis734340159',\n",
       "  'class1iastateedu',\n",
       "  'anyon',\n",
       "  'know',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'graphic',\n",
       "  'chip',\n",
       "  'far',\n",
       "  'lowlevel',\n",
       "  'stuff',\n",
       "  'goe',\n",
       "  'look',\n",
       "  'pretti',\n",
       "  'nice',\n",
       "  'got',\n",
       "  'quadrilater',\n",
       "  'fill',\n",
       "  'command',\n",
       "  'requir',\n",
       "  'four',\n",
       "  'point',\n",
       "  'weitek',\n",
       "  'addressphon',\n",
       "  'number',\n",
       "  'like',\n",
       "  'get',\n",
       "  'inform',\n",
       "  'chip',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'harri',\n",
       "  'corpor',\n",
       "  'jgreen',\n",
       "  'csdharriscom',\n",
       "  'comput',\n",
       "  'system',\n",
       "  'divis',\n",
       "  'thing',\n",
       "  'realli',\n",
       "  'scare',\n",
       "  'person',\n",
       "  'sens',\n",
       "  'humor',\n",
       "  'jonathan',\n",
       "  'winter']]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lemmetisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from nltk.stem import WordNetLemmatizer as wnl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "wnet = wnl()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "nl.download(\"wordnet\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/prajualpillai/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "lem = []\n",
    "for words in cl5:\n",
    "    w = []\n",
    "    for word in words:\n",
    "        w.append(wnet.lemmatize(word))\n",
    "    lem.append(w)\n",
    "lem"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['lerxst',\n",
       "  'wamumdedu',\n",
       "  'thing',\n",
       "  'subject',\n",
       "  'car',\n",
       "  'nntppostinghost',\n",
       "  'rac3wamumdedu',\n",
       "  'organ',\n",
       "  'univers',\n",
       "  'maryland',\n",
       "  'colleg',\n",
       "  'park',\n",
       "  'line',\n",
       "  '15',\n",
       "  'wonder',\n",
       "  'anyon',\n",
       "  'could',\n",
       "  'enlighten',\n",
       "  'car',\n",
       "  'saw',\n",
       "  'day',\n",
       "  '2door',\n",
       "  'sport',\n",
       "  'car',\n",
       "  'look',\n",
       "  'late',\n",
       "  '60',\n",
       "  'earli',\n",
       "  '70',\n",
       "  'call',\n",
       "  'bricklin',\n",
       "  'door',\n",
       "  'realli',\n",
       "  'small',\n",
       "  'addit',\n",
       "  'front',\n",
       "  'bumper',\n",
       "  'separ',\n",
       "  'rest',\n",
       "  'bodi',\n",
       "  'know',\n",
       "  'anyon',\n",
       "  'tellm',\n",
       "  'model',\n",
       "  'name',\n",
       "  'engin',\n",
       "  'spec',\n",
       "  'year',\n",
       "  'product',\n",
       "  'car',\n",
       "  'made',\n",
       "  'histori',\n",
       "  'whatev',\n",
       "  'info',\n",
       "  'funki',\n",
       "  'look',\n",
       "  'car',\n",
       "  'plea',\n",
       "  'email',\n",
       "  'thank',\n",
       "  'il',\n",
       "  'brought',\n",
       "  'neighborhood',\n",
       "  'lerxst'],\n",
       " ['guykuo',\n",
       "  'carsonuwashingtonedu',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'subject',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'poll',\n",
       "  'final',\n",
       "  'call',\n",
       "  'summari',\n",
       "  'final',\n",
       "  'call',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'report',\n",
       "  'keyword',\n",
       "  'si',\n",
       "  'acceler',\n",
       "  'clock',\n",
       "  'upgrad',\n",
       "  'articleid',\n",
       "  'shelley1qvfo9innc3',\n",
       "  'organ',\n",
       "  'univers',\n",
       "  'washington',\n",
       "  'line',\n",
       "  '11',\n",
       "  'nntppostinghost',\n",
       "  'carsonuwashingtonedu',\n",
       "  'fair',\n",
       "  'number',\n",
       "  'brave',\n",
       "  'soul',\n",
       "  'upgrad',\n",
       "  'si',\n",
       "  'clock',\n",
       "  'oscil',\n",
       "  'share',\n",
       "  'experi',\n",
       "  'poll',\n",
       "  'plea',\n",
       "  'send',\n",
       "  'brief',\n",
       "  'messag',\n",
       "  'detail',\n",
       "  'experi',\n",
       "  'procedur',\n",
       "  'top',\n",
       "  'speed',\n",
       "  'attain',\n",
       "  'cpu',\n",
       "  'rate',\n",
       "  'speed',\n",
       "  'add',\n",
       "  'card',\n",
       "  'adapt',\n",
       "  'heat',\n",
       "  'sink',\n",
       "  'hour',\n",
       "  'usag',\n",
       "  'per',\n",
       "  'day',\n",
       "  'floppi',\n",
       "  'disk',\n",
       "  'function',\n",
       "  '800',\n",
       "  '14',\n",
       "  'floppi',\n",
       "  'especi',\n",
       "  'request',\n",
       "  'summar',\n",
       "  'next',\n",
       "  'two',\n",
       "  'day',\n",
       "  'plea',\n",
       "  'add',\n",
       "  'network',\n",
       "  'knowledg',\n",
       "  'base',\n",
       "  'done',\n",
       "  'clock',\n",
       "  'upgrad',\n",
       "  'nt',\n",
       "  'answer',\n",
       "  'poll',\n",
       "  'thank',\n",
       "  'guy',\n",
       "  'kuo',\n",
       "  'guykuo',\n",
       "  'uwashingtonedu'],\n",
       " ['twilli',\n",
       "  'ececnpurdueedu',\n",
       "  'thoma',\n",
       "  'e',\n",
       "  'willi',\n",
       "  'subject',\n",
       "  'pb',\n",
       "  'question',\n",
       "  'organ',\n",
       "  'purdu',\n",
       "  'univers',\n",
       "  'engin',\n",
       "  'comput',\n",
       "  'network',\n",
       "  'distribut',\n",
       "  'usa',\n",
       "  'line',\n",
       "  '36',\n",
       "  'well',\n",
       "  'folk',\n",
       "  'mac',\n",
       "  'plu',\n",
       "  'final',\n",
       "  'gave',\n",
       "  'ghost',\n",
       "  'weekend',\n",
       "  'start',\n",
       "  'life',\n",
       "  '512k',\n",
       "  'way',\n",
       "  'back',\n",
       "  '1985',\n",
       "  'sooo',\n",
       "  'market',\n",
       "  'new',\n",
       "  'machin',\n",
       "  'bit',\n",
       "  'sooner',\n",
       "  'intend',\n",
       "  'look',\n",
       "  'pick',\n",
       "  'powerbook',\n",
       "  '160',\n",
       "  'mayb',\n",
       "  '180',\n",
       "  'bunch',\n",
       "  'question',\n",
       "  'hope',\n",
       "  'somebodi',\n",
       "  'answer',\n",
       "  'anybodi',\n",
       "  'know',\n",
       "  'dirt',\n",
       "  'next',\n",
       "  'round',\n",
       "  'powerbook',\n",
       "  'introduct',\n",
       "  'expect',\n",
       "  'heard',\n",
       "  '185c',\n",
       "  'suppos',\n",
       "  'make',\n",
       "  'appear',\n",
       "  'summer',\n",
       "  'nt',\n",
       "  'heard',\n",
       "  'anymor',\n",
       "  'sinc',\n",
       "  'nt',\n",
       "  'access',\n",
       "  'macleak',\n",
       "  'wonder',\n",
       "  'anybodi',\n",
       "  'info',\n",
       "  'anybodi',\n",
       "  'heard',\n",
       "  'rumor',\n",
       "  'price',\n",
       "  'drop',\n",
       "  'powerbook',\n",
       "  'line',\n",
       "  'like',\n",
       "  'one',\n",
       "  'duo',\n",
       "  'went',\n",
       "  'recent',\n",
       "  'impress',\n",
       "  'display',\n",
       "  '180',\n",
       "  'could',\n",
       "  'probabl',\n",
       "  'swing',\n",
       "  '180',\n",
       "  'got',\n",
       "  '80mb',\n",
       "  'disk',\n",
       "  'rather',\n",
       "  '120',\n",
       "  'nt',\n",
       "  'realli',\n",
       "  'feel',\n",
       "  'much',\n",
       "  'better',\n",
       "  'display',\n",
       "  'yea',\n",
       "  'look',\n",
       "  'great',\n",
       "  'store',\n",
       "  'wow',\n",
       "  'realli',\n",
       "  'good',\n",
       "  'could',\n",
       "  'solicit',\n",
       "  'opinion',\n",
       "  'peopl',\n",
       "  'use',\n",
       "  '160',\n",
       "  '180',\n",
       "  'daytoday',\n",
       "  'worth',\n",
       "  'take',\n",
       "  'disk',\n",
       "  'size',\n",
       "  'money',\n",
       "  'hit',\n",
       "  'get',\n",
       "  'activ',\n",
       "  'display',\n",
       "  'realiz',\n",
       "  'real',\n",
       "  'subject',\n",
       "  'question',\n",
       "  'play',\n",
       "  'around',\n",
       "  'machin',\n",
       "  'comput',\n",
       "  'store',\n",
       "  'breifli',\n",
       "  'figur',\n",
       "  'opinion',\n",
       "  'somebodi',\n",
       "  'actual',\n",
       "  'use',\n",
       "  'machin',\n",
       "  'daili',\n",
       "  'might',\n",
       "  'prove',\n",
       "  'help',\n",
       "  'well',\n",
       "  'hellcat',\n",
       "  'perform',\n",
       "  'thank',\n",
       "  'bunch',\n",
       "  'advanc',\n",
       "  'info',\n",
       "  'could',\n",
       "  'email',\n",
       "  'post',\n",
       "  'summari',\n",
       "  'news',\n",
       "  'read',\n",
       "  'time',\n",
       "  'premium',\n",
       "  'final',\n",
       "  'around',\n",
       "  'corner',\n",
       "  'tom',\n",
       "  'willi',\n",
       "  'twilli',\n",
       "  'ecnpurdueedu',\n",
       "  'purdu',\n",
       "  'electr',\n",
       "  'engin',\n",
       "  'convict',\n",
       "  'danger',\n",
       "  'enemi',\n",
       "  'truth',\n",
       "  'lie',\n",
       "  'f',\n",
       "  'w',\n",
       "  'nietzsch'],\n",
       " ['jgreen',\n",
       "  'amber',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'subject',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'organ',\n",
       "  'harri',\n",
       "  'comput',\n",
       "  'system',\n",
       "  'divis',\n",
       "  'line',\n",
       "  '14',\n",
       "  'distribut',\n",
       "  'world',\n",
       "  'nntppostinghost',\n",
       "  'amberssdcsdharriscom',\n",
       "  'xnewsread',\n",
       "  'tin',\n",
       "  'version',\n",
       "  '11',\n",
       "  'pl9',\n",
       "  'robert',\n",
       "  'jc',\n",
       "  'kyanko',\n",
       "  'rob',\n",
       "  'rjckuucp',\n",
       "  'wrote',\n",
       "  'abraxi',\n",
       "  'iastateedu',\n",
       "  'write',\n",
       "  'articl',\n",
       "  'abraxis734340159',\n",
       "  'class1iastateedu',\n",
       "  'anyon',\n",
       "  'know',\n",
       "  'weitek',\n",
       "  'p9000',\n",
       "  'graphic',\n",
       "  'chip',\n",
       "  'far',\n",
       "  'lowlevel',\n",
       "  'stuff',\n",
       "  'goe',\n",
       "  'look',\n",
       "  'pretti',\n",
       "  'nice',\n",
       "  'got',\n",
       "  'quadrilater',\n",
       "  'fill',\n",
       "  'command',\n",
       "  'requir',\n",
       "  'four',\n",
       "  'point',\n",
       "  'weitek',\n",
       "  'addressphon',\n",
       "  'number',\n",
       "  'like',\n",
       "  'get',\n",
       "  'inform',\n",
       "  'chip',\n",
       "  'joe',\n",
       "  'green',\n",
       "  'harri',\n",
       "  'corpor',\n",
       "  'jgreen',\n",
       "  'csdharriscom',\n",
       "  'comput',\n",
       "  'system',\n",
       "  'divis',\n",
       "  'thing',\n",
       "  'realli',\n",
       "  'scare',\n",
       "  'person',\n",
       "  'sen',\n",
       "  'humor',\n",
       "  'jonathan',\n",
       "  'winter']]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print(cl5[:1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['lerxst', 'wamumdedu', 'thing', 'subject', 'car', 'nntppostinghost', 'rac3wamumdedu', 'organ', 'univers', 'maryland', 'colleg', 'park', 'line', '15', 'wonder', 'anyon', 'could', 'enlighten', 'car', 'saw', 'day', '2door', 'sport', 'car', 'look', 'late', '60', 'earli', '70', 'call', 'bricklin', 'door', 'realli', 'small', 'addit', 'front', 'bumper', 'separ', 'rest', 'bodi', 'know', 'anyon', 'tellm', 'model', 'name', 'engin', 'spec', 'year', 'product', 'car', 'made', 'histori', 'whatev', 'info', 'funki', 'look', 'car', 'pleas', 'email', 'thank', 'il', 'brought', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from sklearn.preprocessing import LabelEncoder as le\n",
    "from sklearn.model_selection import train_test_split as tts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorize"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer as cv\n",
    "cv1 = cv(ngram_range=(1,2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "fin = cv1.fit_transform(cl5[0]).toarray()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "fin"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "print(cv1.get_feature_names())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['15', '2door', '60', '70', 'addit', 'anyon', 'bodi', 'bricklin', 'brought', 'bumper', 'call', 'car', 'colleg', 'could', 'day', 'door', 'earli', 'email', 'engin', 'enlighten', 'front', 'funki', 'histori', 'il', 'info', 'know', 'late', 'lerxst', 'line', 'look', 'made', 'maryland', 'model', 'name', 'neighborhood', 'nntppostinghost', 'organ', 'park', 'pleas', 'product', 'rac3wamumdedu', 'realli', 'rest', 'saw', 'separ', 'small', 'spec', 'sport', 'subject', 'tellm', 'thank', 'thing', 'univers', 'wamumdedu', 'whatev', 'wonder', 'year']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using BERT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tk = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "tk1 = tk.encode(\"travando...pelo valor ta Boa.\",return_tensors='pt')\n",
    "r = model(tk1)\n",
    "r.logits\n",
    "int(torch.argmax(r.logits))+1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "tk1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  101, 11234, 12459, 10351,   119,   119,   119, 12108, 17859, 10546,\n",
       "         28986,   119,   102]])"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "df = pd.read_csv(\"/Users/prajualpillai/Desktop/work/archive/olist_order_reviews_dataset.csv\")\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parabns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "df1 = df[df[\"review_comment_message\"].isnull()==False]\n",
    "df1.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           review_id                          order_id  \\\n",
       "3   e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4   f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "9   8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
       "12  4b49719c8a200003f700d3d986ea1a19  9d6f15f95d01e79bd1349cc208361f09   \n",
       "15  3948b09f7c818e2d86c9a546758b2335  e51478e7e277a83743b6f9991dbfa3fb   \n",
       "\n",
       "    review_score review_comment_title  \\\n",
       "3              5                  NaN   \n",
       "4              5                  NaN   \n",
       "9              4            recomendo   \n",
       "12             4                  NaN   \n",
       "15             5      Super recomendo   \n",
       "\n",
       "                               review_comment_message review_creation_date  \\\n",
       "3               Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4   Parabns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "9   aparelho eficiente. no site a marca do aparelh...  2018-05-22 00:00:00   \n",
       "12    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  2018-02-16 00:00:00   \n",
       "15  Vendedor confivel, produto ok e entrega antes...  2018-05-23 00:00:00   \n",
       "\n",
       "   review_answer_timestamp  \n",
       "3      2017-04-21 22:02:06  \n",
       "4      2018-03-02 10:26:53  \n",
       "9      2018-05-23 16:45:47  \n",
       "12     2018-02-20 10:52:22  \n",
       "15     2018-05-24 03:00:01  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>4</td>\n",
       "      <td>recomendo</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>2018-05-22 00:00:00</td>\n",
       "      <td>2018-05-23 16:45:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>9d6f15f95d01e79bd1349cc208361f09</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "      <td>2018-02-16 00:00:00</td>\n",
       "      <td>2018-02-20 10:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3948b09f7c818e2d86c9a546758b2335</td>\n",
       "      <td>e51478e7e277a83743b6f9991dbfa3fb</td>\n",
       "      <td>5</td>\n",
       "      <td>Super recomendo</td>\n",
       "      <td>Vendedor confivel, produto ok e entrega antes...</td>\n",
       "      <td>2018-05-23 00:00:00</td>\n",
       "      <td>2018-05-24 03:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "def senan(txt):\n",
    "    tk2 = tk.encode(txt,return_tensors=\"pt\")\n",
    "    r = model(tk2)\n",
    "    r.logits\n",
    "    return(int(torch.argmax(r.logits))+1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "d = {\"Score\":[]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in df1[\"review_comment_message\"]:\n",
    "    d[\"Score\"].append(senan(i))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "d"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Score': [3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  ...]}"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning through BERT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
    "model = AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|| 647/647 [00:00<00:00, 157kB/s]\n",
      "Downloading: 100%|| 438M/438M [01:11<00:00, 6.13MB/s]\n",
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|| 43.0/43.0 [00:00<00:00, 10.9kB/s]\n",
      "Downloading: 100%|| 210k/210k [00:00<00:00, 563kB/s]\n",
      "Downloading: 100%|| 2.00/2.00 [00:00<00:00, 590B/s]\n",
      "Downloading: 100%|| 112/112 [00:00<00:00, 26.3kB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from transformers import pipeline  #for accessing pretrained model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x_tr = tk(X_train,truncation=True,padding=True)\n",
    "x_tst = tk(X_test,truncation=True,padding=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f9ce5cb2f20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "#model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated  Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-df6fcd6b7f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0;31m# the instantiated  Transformers model to be trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0;31m# training arguments, defined above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m             \u001b[0;31m# evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}